{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWpDxn9NKiUj"
      },
      "outputs": [],
      "source": [
        "# âœ… Imports\n",
        "# Cross domain testing result source domain Hotel and target domain Restaurant\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, accuracy_score, f1_score,\n",
        "    precision_score, recall_score, roc_auc_score, roc_curve\n",
        ")\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# âœ… Paths\n",
        "sbert_model_path = '/content/drive/MyDrive/sbert_hotel_doctor_restaurant_model'\n",
        "hotel_path = '/content/drive/MyDrive/LIWC_ hotel_readability_cleaned.csv'\n",
        "restaurant_path = '/content/drive/MyDrive/LIWC_ restaurant_readability_cleaned.csv'\n",
        "\n",
        "text_col = 'review'\n",
        "\n",
        "# âœ… Load SBERT\n",
        "sbert = SentenceTransformer(sbert_model_path)\n",
        "\n",
        "# âœ… Load datasets\n",
        "hotel_df = pd.read_csv(hotel_path)\n",
        "restaurant_df = pd.read_csv(restaurant_path)\n",
        "\n",
        "# âœ… Normalize labels\n",
        "def normalize_label(x):\n",
        "    x = str(x).strip().lower()\n",
        "    if x in ['truthful', 'real', '0']: return 0\n",
        "    if x in ['deceptive', 'fake', '1']: return 1\n",
        "    return None\n",
        "\n",
        "hotel_df['label'] = hotel_df['label'].apply(normalize_label)\n",
        "restaurant_df['label'] = restaurant_df['label'].apply(normalize_label)\n",
        "\n",
        "# âœ… Drop invalid rows\n",
        "hotel_df.dropna(subset=[text_col, 'label'], inplace=True)\n",
        "restaurant_df.dropna(subset=[text_col, 'label'], inplace=True)\n",
        "\n",
        "# âœ… Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(hotel_df['label'])         # âœ… Train on hotel\n",
        "y_test = le.transform(restaurant_df['label'])         # âœ… Test on restaurant\n",
        "\n",
        "# âœ… SBERT embeddings\n",
        "X_text_train = sbert.encode(hotel_df[text_col].tolist(), show_progress_bar=True)\n",
        "X_text_test = sbert.encode(restaurant_df[text_col].tolist(), show_progress_bar=True)\n",
        "\n",
        "# âœ… Compute class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
        "\n",
        "# âœ… Model definition (text only)\n",
        "TEXT_DIM = X_text_train.shape[1]\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "text_input = Input(shape=(TEXT_DIM,), name='text_embedding_input')\n",
        "\n",
        "x = Dense(256, activation='relu', name='text_dense_1')(text_input)\n",
        "x = Dropout(0.3, name='text_dropout_1')(x)\n",
        "x = Dense(128, activation='relu', name='text_dense_2')(x)\n",
        "x = Dropout(0.2, name='fusion_dropout')(x)\n",
        "x = Dense(64, activation='relu', name='fusion_dense')(x)\n",
        "output = Dense(NUM_CLASSES, activation='softmax', name='classifier')(x)\n",
        "\n",
        "model = Model(inputs=text_input, outputs=output)\n",
        "model.compile(optimizer=Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# âœ… Train model\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(\n",
        "    X_text_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# âœ… Predict and tune threshold\n",
        "y_pred_probs = model.predict(X_text_test)\n",
        "best_f1 = 0\n",
        "best_thresh = 0.6\n",
        "\n",
        "for t in np.arange(0.3, 0.71, 0.05):\n",
        "    y_pred_thresh = (y_pred_probs[:, 1] > t).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred_thresh, average='weighted')\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_thresh = t\n",
        "\n",
        "# âœ… Final prediction and evaluation\n",
        "y_pred_final = (y_pred_probs[:, 1] > best_thresh).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred_final)\n",
        "precision = precision_score(y_test, y_pred_final)\n",
        "recall = recall_score(y_test, y_pred_final)\n",
        "f1 = f1_score(y_test, y_pred_final, average='weighted')\n",
        "auc_score = roc_auc_score(y_test, y_pred_probs[:, 1])\n",
        "report = classification_report(y_test, y_pred_final, digits=4)\n",
        "matrix = confusion_matrix(y_test, y_pred_final)\n",
        "\n",
        "# âœ… Print metrics\n",
        "print(\"âœ… Cross-domain Accuracy (Hotel â†’ Restaurant):\", acc)\n",
        "print(\"âœ… Best Threshold:\", best_thresh)\n",
        "print(\"âœ… Precision:\", precision)\n",
        "print(\"âœ… Recall:\", recall)\n",
        "print(\"âœ… F1 Score (weighted):\", f1)\n",
        "print(\"âœ… AUC Score:\", auc_score)\n",
        "print(\"\\nâœ… Classification Report:\\n\", report)\n",
        "print(\"âœ… Confusion Matrix:\\n\", matrix)\n",
        "\n",
        "# âœ… Plot confusion matrix heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# âœ… Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs[:, 1])\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.4f}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Cross domain testing result source domain Hotel and target domain Doctor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Bidirectional, LSTM, Conv1D, GlobalMaxPooling1D, Reshape, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sbert_model_path = '/content/drive/MyDrive/sbert_hotel_doctor_restaurant_model'\n",
        "doctor_path = '/content/drive/MyDrive/LIWC_doctor_readability_cleaned.csv'\n",
        "hotel_path = '/content/drive/MyDrive/LIWC_ hotel_readability_cleaned.csv'\n",
        "text_col = 'review'\n",
        "numeric_cols = ['FleschReadingEase', 'SMOGIndex', 'DaleChall', 'sentimentv', 'WC', 'Analytic', 'Authentic', 'BigWords']\n",
        "\n",
        "sbert = SentenceTransformer(sbert_model_path)\n",
        "\n",
        "doctor_df = pd.read_csv(doctor_path)\n",
        "hotel_df = pd.read_csv(hotel_path)\n",
        "\n",
        "\n",
        "def normalize_label(x):\n",
        "    x = str(x).strip().lower()\n",
        "    if x in ['truthful', 'real', '0']: return 0\n",
        "    if x in ['deceptive', 'fake', '1']: return 1\n",
        "    return None\n",
        "print(\"Hotel labels:\", hotel_df['label'].unique())\n",
        "print(\"doctor labels:\", doctor_df['label'].unique())\n",
        "\n",
        "doctor_df['label'] = doctor_df['label'].apply(normalize_label)\n",
        "hotel_df['label'] = hotel_df['label'].apply(normalize_label)\n",
        "\n",
        "\n",
        "doctor_df.dropna(subset=[text_col, 'label'] + numeric_cols, inplace=True)\n",
        "hotel_df.dropna(subset=[text_col, 'label'] + numeric_cols, inplace=True)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(hotel_df['label'])\n",
        "y_test = le.transform(doctor_df['label'])\n",
        "\n",
        "X_text_train = sbert.encode(hotel_df[text_col].tolist(), show_progress_bar=True)\n",
        "X_text_test = sbert.encode(doctor_df[text_col].tolist(), show_progress_bar=True)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_num_train = scaler.fit_transform(hotel_df[numeric_cols])\n",
        "X_num_test = scaler.transform(doctor_df[numeric_cols])\n",
        "\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
        "\n",
        "\n",
        "TEXT_DIM = X_text_train.shape[1]\n",
        "NUMERIC_DIM = X_num_train.shape[1]\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "text_input = Input(shape=(TEXT_DIM,), name='text_embedding_input')\n",
        "numeric_input = Input(shape=(NUMERIC_DIM,), name='numeric_features_input')\n",
        "\n",
        "x = Reshape((TEXT_DIM, 1))(text_input)\n",
        "x = Conv1D(100, kernel_size=1, activation='sigmoid', padding='same')(x)\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "\n",
        "x_num = Dense(4, activation='sigmoid')(numeric_input)\n",
        "x_combined = Concatenate()([x, x_num])\n",
        "x_combined = Dropout(0.2)(x_combined)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x_combined)\n",
        "\n",
        "model = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model.compile(optimizer=Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit([X_text_train, X_num_train], y_train,\n",
        "          validation_split=0.1,\n",
        "          epochs=5,\n",
        "          batch_size=64,\n",
        "          class_weight=class_weight_dict,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1)\n",
        "\n",
        "y_pred_probs = model.predict([X_text_test, X_num_test])\n",
        "best_f1 = 0\n",
        "best_thresh = 0.6\n",
        "\n",
        "for t in np.arange(0.3, 0.71, 0.05):\n",
        "    y_pred_thresh = (y_pred_probs[:, 1] > t).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred_thresh, average='weighted')\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_thresh = t\n",
        "\n",
        "y_pred_final = (y_pred_probs[:, 1] > best_thresh).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred_final)\n",
        "precision = precision_score(y_test, y_pred_final)\n",
        "recall = recall_score(y_test, y_pred_final)\n",
        "f1 = f1_score(y_test, y_pred_final, average='weighted')\n",
        "auc_score = roc_auc_score(y_test, y_pred_probs[:, 1])\n",
        "report = classification_report(y_test, y_pred_final, digits=4)\n",
        "matrix = confusion_matrix(y_test, y_pred_final)\n",
        "\n",
        "print(\"âœ… Cross-domain Accuracy (Hotel â†’ Doctor):\", acc)\n"
      ],
      "metadata": {
        "id": "kJSaF8fWKwEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training and testing on Hotel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Bidirectional, LSTM, Conv1D, GlobalMaxPooling1D, Reshape, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sbert_model_path = '/content/drive/MyDrive/sbert_hotel_doctor_restaurant_model'\n",
        "hotel_path = '/content/drive/MyDrive/LIWC_ hotel_readability_cleaned.csv'\n",
        "text_col = 'review'\n",
        "numeric_cols = ['FleschReadingEase', 'SMOGIndex', 'DaleChall', 'sentimentv', 'WC', 'Analytic', 'Authentic', 'BigWords']\n",
        "\n",
        "sbert = SentenceTransformer(sbert_model_path)\n",
        "\n",
        "hotel_df = pd.read_csv(hotel_path)\n",
        "\n",
        "def normalize_label(x):\n",
        "    x = str(x).strip().lower()\n",
        "    if x in ['truthful', 'real', '0']: return 0\n",
        "    if x in ['deceptive', 'fake', '1']: return 1\n",
        "    return None\n",
        "\n",
        "hotel_df['label'] = hotel_df['label'].apply(normalize_label)\n",
        "hotel_df.dropna(subset=[text_col, 'label'] + numeric_cols, inplace=True)\n",
        "\n",
        "train_df, test_df = train_test_split(hotel_df, test_size=0.2, random_state=42, stratify=hotel_df['label'])\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(train_df['label'])\n",
        "y_test = le.transform(test_df['label'])\n",
        "\n",
        "X_text_train = sbert.encode(train_df[text_col].tolist(), show_progress_bar=True)\n",
        "X_text_test = sbert.encode(test_df[text_col].tolist(), show_progress_bar=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_num_train = scaler.fit_transform(train_df[numeric_cols])\n",
        "X_num_test = scaler.transform(test_df[numeric_cols])\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
        "TEXT_DIM = X_text_train.shape[1]\n",
        "NUMERIC_DIM = X_num_train.shape[1]\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "text_input = Input(shape=(TEXT_DIM,), name='text_embedding_input')\n",
        "numeric_input = Input(shape=(NUMERIC_DIM,), name='numeric_features_input')\n",
        "\n",
        "x = Reshape((TEXT_DIM, 1))(text_input)\n",
        "x = Conv1D(100, kernel_size=3, activation='sigmoid', padding='same')(x)\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "\n",
        "x_num = Dense(16, activation='sigmoid')(numeric_input)\n",
        "x_combined = Concatenate()([x, x_num])\n",
        "x_combined = Dropout(0.3)(x_combined)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x_combined)\n",
        "\n",
        "model = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model.compile(optimizer=Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit([X_text_train, X_num_train], y_train,\n",
        "          validation_split=0.2,\n",
        "          epochs=5,\n",
        "          batch_size=32,\n",
        "          class_weight=class_weight_dict,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1)\n",
        "e\n",
        "y_pred_probs = model.predict([X_text_test, X_num_test])\n",
        "best_f1 = 0\n",
        "best_thresh = 0.6\n",
        "\n",
        "for t in np.arange(0.3, 0.71, 0.05):\n",
        "    y_pred_thresh = (y_pred_probs[:, 1] > t).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred_thresh, average='weighted')\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_thresh = t\n",
        "\n",
        "y_pred_final = (y_pred_probs[:, 1] > best_thresh).astype(int)\n",
        "acc = accuracy_score(y_test, y_pred_final)\n",
        "precision = precision_score(y_test, y_pred_final)\n",
        "recall = recall_score(y_test, y_pred_final)\n",
        "f1 = f1_score(y_test, y_pred_final, average='weighted')\n",
        "auc_score = roc_auc_score(y_test, y_pred_probs[:, 1])\n",
        "report = classification_report(y_test, y_pred_final, digits=4)\n",
        "matrix = confusion_matrix(y_test, y_pred_final)\n",
        "\n",
        "print(\" In-Domain Accuracy (Hotel):\", acc)\n"
      ],
      "metadata": {
        "id": "KLAmPD5hK64U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Cross domain testing result source domain Hotel and target domain Doctor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Bidirectional, LSTM, Conv1D, GlobalMaxPooling1D, Reshape, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# âœ… Paths\n",
        "sbert_model_path = '/content/drive/MyDrive/sbert_hotel_doctor_restaurant_model'\n",
        "doctor_path = '/content/drive/MyDrive/LIWC_doctor_readability_cleaned.csv'\n",
        "hotel_path = '/content/drive/MyDrive/LIWC_ hotel_readability_cleaned.csv'\n",
        "text_col = 'review'\n",
        "numeric_cols = ['FleschReadingEase', 'SMOGIndex', 'DaleChall', 'sentimentv', 'WC', 'Analytic', 'Authentic', 'BigWords']\n",
        "\n",
        "# âœ… Load SBERT\n",
        "sbert = SentenceTransformer(sbert_model_path)\n",
        "\n",
        "# âœ… Load datasets\n",
        "doctor_df = pd.read_csv(doctor_path)\n",
        "hotel_df = pd.read_csv(hotel_path)\n",
        "\n",
        "# âœ… Normalize labels\n",
        "def normalize_label(x):\n",
        "    x = str(x).strip().lower()\n",
        "    if x in ['truthful', 'real', '0']: return 0\n",
        "    if x in ['deceptive', 'fake', '1']: return 1\n",
        "    return None\n",
        "print(\"Hotel labels:\", hotel_df['label'].unique())\n",
        "print(\"doctor labels:\", doctor_df['label'].unique())\n",
        "\n",
        "doctor_df['label'] = doctor_df['label'].apply(normalize_label)\n",
        "hotel_df['label'] = hotel_df['label'].apply(normalize_label)\n",
        "\n",
        "\n",
        "doctor_df.dropna(subset=[text_col, 'label'] + numeric_cols, inplace=True)\n",
        "hotel_df.dropna(subset=[text_col, 'label'] + numeric_cols, inplace=True)\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(hotel_df['label'])\n",
        "y_test = le.transform(doctor_df['label'])\n",
        "X_text_train = sbert.encode(hotel_df[text_col].tolist(), show_progress_bar=True)\n",
        "X_text_test = sbert.encode(doctor_df[text_col].tolist(), show_progress_bar=True)\n",
        "scaler = StandardScaler()\n",
        "X_num_train = scaler.fit_transform(hotel_df[numeric_cols])\n",
        "X_num_test = scaler.transform(doctor_df[numeric_cols])\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
        "\n",
        "TEXT_DIM = X_text_train.shape[1]\n",
        "NUMERIC_DIM = X_num_train.shape[1]\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "text_input = Input(shape=(TEXT_DIM,), name='text_embedding_input')\n",
        "numeric_input = Input(shape=(NUMERIC_DIM,), name='numeric_features_input')\n",
        "\n",
        "x = Reshape((TEXT_DIM, 1))(text_input)\n",
        "x = Conv1D(100, kernel_size=1, activation='sigmoid', padding='same')(x)\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "\n",
        "x_num = Dense(4, activation='sigmoid')(numeric_input)\n",
        "x_combined = Concatenate()([x, x_num])\n",
        "x_combined = Dropout(0.2)(x_combined)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x_combined)\n",
        "\n",
        "model = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model.compile(optimizer=Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit([X_text_train, X_num_train], y_train,\n",
        "          validation_split=0.1,\n",
        "          epochs=5,\n",
        "          batch_size=32,\n",
        "          class_weight=class_weight_dict,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1)\n",
        "\n",
        "y_pred_probs = model.predict([X_text_test, X_num_test])\n",
        "best_f1 = 0\n",
        "best_thresh = 0.6\n",
        "\n",
        "for t in np.arange(0.3, 0.71, 0.05):\n",
        "    y_pred_thresh = (y_pred_probs[:, 1] > t).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred_thresh, average='weighted')\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_thresh = t\n",
        "\n",
        "y_pred_final = (y_pred_probs[:, 1] > best_thresh).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred_final)\n",
        "precision = precision_score(y_test, y_pred_final)\n",
        "recall = recall_score(y_test, y_pred_final)\n",
        "f1 = f1_score(y_test, y_pred_final, average='weighted')\n",
        "auc_score = roc_auc_score(y_test, y_pred_probs[:, 1])\n",
        "report = classification_report(y_test, y_pred_final, digits=4)\n",
        "matrix = confusion_matrix(y_test, y_pred_final)\n",
        "\n",
        "print(\" Cross-domain Accuracy (Hotel â†’ Restaurant):\", acc)\n",
        "\n"
      ],
      "metadata": {
        "id": "qvMC1b8LK7uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Part 2: Readability Calculation for Doctor Reviews\n",
        "\n",
        "# !pip install textstat pandas\n",
        "\n",
        "import pandas as pd\n",
        "import textstat\n",
        "\n",
        "# âœ… Load cleaned doctor reviews\n",
        "restaurant_df = pd.read_csv(\"/content/drive/MyDrive/restaurant_cleaned_reviews.csv\")\n",
        "restaurant_df.dropna(subset=['clean_review'], inplace=True)\n",
        "\n",
        "# âœ… Function to calculate readability\n",
        "def compute_readability(text):\n",
        "    return {\n",
        "        \"FleschReadingEase\": textstat.flesch_reading_ease(text),\n",
        "        \"FleschKincaidGrade\": textstat.flesch_kincaid_grade(text),\n",
        "        \"SMOGIndex\": textstat.smog_index(text),\n",
        "        \"GunningFog\": textstat.gunning_fog(text),\n",
        "        \"AutomatedReadability\": textstat.automated_readability_index(text),\n",
        "        \"DaleChall\": textstat.dale_chall_readability_score(text)\n",
        "    }\n",
        "\n",
        "# âœ… Calculate readability scores\n",
        "readability_scores = restaurant_df['clean_review'].apply(compute_readability)\n",
        "readability_df = pd.DataFrame(list(readability_scores))\n",
        "\n",
        "# âœ… Combine results with the original dataframe\n",
        "restaurant_df_final = pd.concat([restaurant_df.reset_index(drop=True), readability_df], axis=1)\n",
        "\n",
        "# âœ… Show average readability\n",
        "print(\"ðŸ“Š Average Readability Scores (restaurant Reviews):\")\n",
        "print(readability_df.mean())\n",
        "\n",
        "# âœ… Optional: Save results to CSV\n",
        "restaurant_df_final.to_csv(\"/content/drive/MyDrive/restaurant_readability_cleaned.csv\", index=False)"
      ],
      "metadata": {
        "id": "WasRyOqeMMHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mix doctor, restaurant, and hotel dataset\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, accuracy_score,\n",
        "    f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, Dropout, Bidirectional, LSTM, Conv1D,\n",
        "    GlobalMaxPooling1D, Reshape, Concatenate, GaussianNoise\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# -----------------------------\n",
        "# Paths and config\n",
        "# -----------------------------\n",
        "sbert_model_path = '/content/drive/MyDrive/sbert_hotel_doctor_restaurant_model'\n",
        "doctor_path = '/content/drive/MyDrive/LIWC_doctor_readability_cleaned.csv'\n",
        "restaurant_path = '/content/drive/MyDrive/LIWC_ restaurant_readability_cleaned.csv'\n",
        "hotel_path = '/content/drive/MyDrive/LIWC_ hotel_readability_cleaned.csv'\n",
        "\n",
        "text_col = 'review'\n",
        "numeric_cols = [\n",
        "    'FleschReadingEase', 'SMOGIndex', 'DaleChall', 'sentimentv',\n",
        "    'WC', 'Analytic', 'Authentic', 'BigWords'\n",
        "]\n",
        "\n",
        "\n",
        "sbert = SentenceTransformer(sbert_model_path)\n",
        "doctor_df = pd.read_csv(doctor_path)\n",
        "restaurant_df = pd.read_csv(restaurant_path)\n",
        "hotel_df = pd.read_csv(hotel_path)\n",
        "\n",
        "\n",
        "def normalize_label(x):\n",
        "    x = str(x).strip().lower()\n",
        "    if x in ['truthful', 'real', '0']:\n",
        "        return 0\n",
        "    if x in ['deceptive', 'fake', '1']:\n",
        "        return 1\n",
        "    return None\n",
        "\n",
        "for df in (doctor_df, restaurant_df, hotel_df):\n",
        "    df['label'] = df['label'].apply(normalize_label)\n",
        "    df.dropna(subset=[text_col, 'label'] + numeric_cols, inplace=True)\n",
        "\n",
        "-\n",
        "combined_df = pd.concat([doctor_df, restaurant_df, hotel_df], ignore_index=True)\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(combined_df['label'])\n",
        "\n",
        "\n",
        "print(\"Encoding text with SBERT...\")\n",
        "X_text = sbert.encode(combined_df[text_col].tolist(), show_progress_bar=True)\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "X_text = X_text + np.random.normal(0, 0.05, X_text.shape)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_num = scaler.fit_transform(combined_df[numeric_cols])\n",
        "\n",
        "\n",
        "X_text_train, X_text_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
        "    X_text, X_num, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "TEXT_DIM = X_text_train.shape[1]\n",
        "NUMERIC_DIM = X_num_train.shape[1]\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "text_input = Input(shape=(TEXT_DIM,), name='text_input')\n",
        "numeric_input = Input(shape=(NUMERIC_DIM,), name='numeric_input')\n",
        "\n",
        "\n",
        "x = Reshape((TEXT_DIM, 1))(text_input)\n",
        "x = GaussianNoise(0.1)(x)\n",
        "x = Conv1D(16, kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = Bidirectional(LSTM(16, return_sequences=True))(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "\n",
        "x_num = Dense(8, activation='tanh')(numeric_input)\n",
        "\n",
        "# combine\n",
        "x_combined = Concatenate()([x, x_num])\n",
        "x_combined = Dropout(0.7)(x_combined)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x_combined)\n",
        "\n",
        "model = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model.compile(optimizer=Adam(learning_rate=3e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    [X_text_train, X_num_train], y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "y_pred_probs = model.predict([X_text_test, X_num_test])\n",
        "y_pred_final = (y_pred_probs[:, 1] > 0.5).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred_final)\n",
        "precision = precision_score(y_test, y_pred_final)\n",
        "recall = recall_score(y_test, y_pred_final)\n",
        "f1 = f1_score(y_test, y_pred_final, average='macro')\n",
        "auc_score = roc_auc_score(y_test, y_pred_probs[:, 1])\n",
        "report = classification_report(y_test, y_pred_final, digits=4)\n",
        "matrix = confusion_matrix(y_test, y_pred_final)\n",
        "\n"
      ],
      "metadata": {
        "id": "LWoLQNGMMaQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training and testing on Doctor\n",
        "# âœ… Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Bidirectional, LSTM, Conv1D, GlobalMaxPooling1D, Reshape, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# âœ… Paths\n",
        "sbert_model_path = '/content/drive/MyDrive/sbert_hotel_doctor_restaurant_model'\n",
        "doctor_path = '/content/drive/MyDrive/LIWC_doctor_readability_cleaned.csv'\n",
        "text_col = 'review'\n",
        "numeric_cols = ['FleschReadingEase', 'SMOGIndex', 'DaleChall', 'sentimentv', 'WC', 'Analytic', 'Authentic', 'BigWords']\n",
        "\n",
        "# âœ… Load SBERT\n",
        "sbert = SentenceTransformer(sbert_model_path)\n",
        "\n",
        "# âœ… Load and prepare dataset\n",
        "doctor_df = pd.read_csv(doctor_path)\n",
        "\n",
        "def normalize_label(x):\n",
        "    x = str(x).strip().lower()\n",
        "    if x in ['truthful', 'real', '0']: return 0\n",
        "    if x in ['deceptive', 'fake', '1']: return 1\n",
        "    return None\n",
        "\n",
        "doctor_df['label'] = doctor_df['label'].apply(normalize_label)\n",
        "doctor_df.dropna(subset=[text_col, 'label'] + numeric_cols, inplace=True)\n",
        "\n",
        "# âœ… Train-test split (same domain)\n",
        "train_df, test_df = train_test_split(doctor_df, test_size=0.2, random_state=42, stratify=doctor_df['label'])\n",
        "\n",
        "# âœ… Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(train_df['label'])\n",
        "y_test = le.transform(test_df['label'])\n",
        "\n",
        "# âœ… SBERT embeddings\n",
        "X_text_train = sbert.encode(train_df[text_col].tolist(), show_progress_bar=True)\n",
        "X_text_test = sbert.encode(test_df[text_col].tolist(), show_progress_bar=True)\n",
        "\n",
        "# âœ… Numeric features\n",
        "scaler = StandardScaler()\n",
        "X_num_train = scaler.fit_transform(train_df[numeric_cols])\n",
        "X_num_test = scaler.transform(test_df[numeric_cols])\n",
        "\n",
        "# âœ… Compute class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
        "\n",
        "# âœ… Model architecture\n",
        "TEXT_DIM = X_text_train.shape[1]\n",
        "NUMERIC_DIM = X_num_train.shape[1]\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "text_input = Input(shape=(TEXT_DIM,), name='text_embedding_input')\n",
        "numeric_input = Input(shape=(NUMERIC_DIM,), name='numeric_features_input')\n",
        "\n",
        "x = Reshape((TEXT_DIM, 1))(text_input)\n",
        "x = Conv1D(128, kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "\n",
        "x_num = Dense(64, activation='relu')(numeric_input)\n",
        "x_combined = Concatenate()([x, x_num])\n",
        "x_combined = Dropout(0.5)(x_combined)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x_combined)\n",
        "\n",
        "model = Model(inputs=[text_input, numeric_input], outputs=output)\n",
        "model.compile(optimizer=Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# âœ… Train model\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit([X_text_train, X_num_train], y_train,\n",
        "          validation_split=0.2,\n",
        "          epochs=10,\n",
        "          batch_size=10,\n",
        "          class_weight=class_weight_dict,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1)\n",
        "\n",
        "# âœ… Predict and evaluate\n",
        "y_pred_probs = model.predict([X_text_test, X_num_test])\n",
        "best_f1 = 0\n",
        "best_thresh = 0.5\n",
        "\n",
        "for t in np.arange(0.3, 0.71, 0.05):\n",
        "    y_pred_thresh = (y_pred_probs[:, 1] > t).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred_thresh, average='weighted')\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_thresh = t\n",
        "\n",
        "y_pred_final = (y_pred_probs[:, 1] > best_thresh).astype(int)\n",
        "\n",
        "# âœ… Metrics\n",
        "acc = accuracy_score(y_test, y_pred_final)\n",
        "precision = precision_score(y_test, y_pred_final)\n",
        "recall = recall_score(y_test, y_pred_final)\n",
        "f1 = f1_score(y_test, y_pred_final, average='weighted')\n",
        "auc_score = roc_auc_score(y_test, y_pred_probs[:, 1])\n",
        "report = classification_report(y_test, y_pred_final, digits=4)\n",
        "matrix = confusion_matrix(y_test, y_pred_final)\n",
        "\n",
        "# âœ… Print results\n",
        "print(\"âœ… In-Domain Accuracy (Doctor):\", acc)\n",
        "print(\"âœ… Best Threshold:\", best_thresh)\n",
        "print(\"âœ… Precision:\", precision)\n",
        "print(\"âœ… Recall:\", recall)\n",
        "print(\"âœ… F1 Score (weighted):\", f1)\n",
        "print(\"âœ… AUC Score:\", auc_score)\n",
        "print(\"\\nâœ… Classification Report:\\n\", report)\n",
        "print(\"âœ… Confusion Matrix:\\n\", matrix)\n",
        "\n",
        "# âœ… Confusion matrix plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# âœ… ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs[:, 1])\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.4f}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QJxvz0NuNyND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "import seaborn as sns\n",
        "sent_i = SentimentIntensityAnalyzer()\n",
        "\n",
        "def vadar_sentiment(text):\n",
        "    \"\"\" Calculate and return the nltk vadar (lexicon method) sentiment \"\"\"\n",
        "    return sent_i.polarity_scores(text)['compound']\n",
        "\n",
        "# create new column for vadar compound sentiment score\n",
        "df['vadar compound'] = df.iloc[:,6].apply(vadar_sentiment)\n",
        "\n",
        "def categorise_sentiment(sentiment, neg_threshold=-0.05, pos_threshold=0.05):\n",
        "    \"\"\" categorise the sentiment value as positive (1), negative (-1)\n",
        "        or neutral (0) based on given thresholds \"\"\"\n",
        "    if sentiment < neg_threshold:\n",
        "        label = 'negative'\n",
        "    elif sentiment > pos_threshold:\n",
        "        label = 'positive'\n",
        "    else:\n",
        "        label = 'neutral'\n",
        "    return label\n",
        "\n",
        "# new col with vadar sentiment label based on vadar compound score\n",
        "df['vadar sentiment'] = df['vadar compound'].apply(categorise_sentiment)"
      ],
      "metadata": {
        "id": "jm_Zec-qYSg9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}